

### Overview 

*slides* : https://docs.google.com/presentation/d/1C9IaAwHoWcc4RSTqo-pCoN3h0nCgqV2JEYZUJunv_9Q/edit?usp=sharing

from video (1-4) it's the basics of how RAG WORKS and why it is needed ?

1. **why it's needed** : llm's are trained on a lot of data, but they don't have enough context on your own private data to help you. for example, if i ask how much square feet my house is - it won't know because it hasn't seen the data
2. **how it works** : so, to solve this problem we use retrieval augmented generation 
    - *retrieval* : retrieves a set of documents that are most suitable to answer your question using similarity search in vector space
    - *augmented* : your questions is augmented (made better / or something is added to it) to make it full of context, from which llm can find the answer
    - *generation* : the generation is the last step in which your context is taken into account and then result is generated by the llm
      
3. **technical details and steps** : a whole RAG Setup consists of the following steps
   - **ingestion** : the source data is ingested into a database and collected that is relevant to the questions your user can ask, for example : your company's SOP regarding client calls, as the document is updated regularly, it is ingested and updated in the rag pipeline too at regular intervals
   - **indexing** : the text from the document is parsed, then split in to small chunks of data, for better and efficient retrieval, and then it is converted into vectors - and stored into a vector database - why we use vectors?  - because in a vector space, similar vectors will be closer to each other, and hence we can use algorithms such as nearest neighbour and etc, to get the most relevent doc to our questions
   - **retrieval** : this is the step 
  

